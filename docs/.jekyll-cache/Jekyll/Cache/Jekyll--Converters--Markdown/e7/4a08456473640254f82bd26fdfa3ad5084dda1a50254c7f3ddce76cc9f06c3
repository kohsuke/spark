I";<p>Spark uses Hadoop client libraries for HDFS and YARN. Starting in version Spark 1.4, the project packages &#8220;Hadoop free&#8221; builds that lets you more easily connect a single Spark binary to any Hadoop version. To use these builds, you need to modify <code>SPARK_DIST_CLASSPATH</code> to include Hadoop&#8217;s package jars. The most convenient place to do this is by adding an entry in <code>conf/spark-env.sh</code>.</p>

<p>This page describes how to connect Spark to Hadoop for different types of distributions.</p>

<h1 id="apache-hadoop">Apache Hadoop</h1>
<p>For Apache distributions, you can use Hadoop&#8217;s &#8216;classpath&#8217; command. For instance:</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c">### in conf/spark-env.sh ###</span>

<span class="c"># If 'hadoop' binary is on your PATH</span>
<span class="nb">export </span><span class="nv">SPARK_DIST_CLASSPATH</span><span class="o">=</span><span class="si">$(</span>hadoop classpath<span class="si">)</span>

<span class="c"># With explicit path to 'hadoop' binary</span>
<span class="nb">export </span><span class="nv">SPARK_DIST_CLASSPATH</span><span class="o">=</span><span class="si">$(</span>/path/to/hadoop/bin/hadoop classpath<span class="si">)</span>

<span class="c"># Passing a Hadoop configuration directory</span>
<span class="nb">export </span><span class="nv">SPARK_DIST_CLASSPATH</span><span class="o">=</span><span class="si">$(</span>hadoop <span class="nt">--config</span> /path/to/configs classpath<span class="si">)</span></code></pre></figure>

:ET