I"‚<p>This page describes clustering algorithms in MLlib.
The <a href="mllib-clustering.html">guide for clustering in the RDD-based API</a> also has relevant information
about these algorithms.</p>

<p><strong>Table of Contents</strong></p>

<ul id="markdown-toc">
  <li><a href="#k-means" id="markdown-toc-k-means">K-means</a>    <ul>
      <li><a href="#input-columns" id="markdown-toc-input-columns">Input Columns</a></li>
      <li><a href="#output-columns" id="markdown-toc-output-columns">Output Columns</a></li>
    </ul>
  </li>
  <li><a href="#latent-dirichlet-allocation-lda" id="markdown-toc-latent-dirichlet-allocation-lda">Latent Dirichlet allocation (LDA)</a></li>
  <li><a href="#bisecting-k-means" id="markdown-toc-bisecting-k-means">Bisecting k-means</a></li>
  <li><a href="#gaussian-mixture-model-gmm" id="markdown-toc-gaussian-mixture-model-gmm">Gaussian Mixture Model (GMM)</a>    <ul>
      <li><a href="#input-columns-1" id="markdown-toc-input-columns-1">Input Columns</a></li>
      <li><a href="#output-columns-1" id="markdown-toc-output-columns-1">Output Columns</a></li>
    </ul>
  </li>
  <li><a href="#power-iteration-clustering-pic" id="markdown-toc-power-iteration-clustering-pic">Power Iteration Clustering (PIC)</a></li>
</ul>

<h2 id="k-means">K-means</h2>

<p><a href="http://en.wikipedia.org/wiki/K-means_clustering">k-means</a> is one of the
most commonly used clustering algorithms that clusters the data points into a
predefined number of clusters. The MLlib implementation includes a parallelized
variant of the <a href="http://en.wikipedia.org/wiki/K-means%2B%2B">k-means++</a> method
called <a href="http://theory.stanford.edu/~sergei/papers/vldb12-kmpar.pdf">kmeans||</a>.</p>

<p><code>KMeans</code> is implemented as an <code>Estimator</code> and generates a <code>KMeansModel</code> as the base model.</p>

<h3 id="input-columns">Input Columns</h3>

<table class="table">
  <thead>
    <tr>
      <th align="left">Param name</th>
      <th align="left">Type(s)</th>
      <th align="left">Default</th>
      <th align="left">Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>featuresCol</td>
      <td>Vector</td>
      <td>"features"</td>
      <td>Feature vector</td>
    </tr>
  </tbody>
</table>

<h3 id="output-columns">Output Columns</h3>

<table class="table">
  <thead>
    <tr>
      <th align="left">Param name</th>
      <th align="left">Type(s)</th>
      <th align="left">Default</th>
      <th align="left">Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>predictionCol</td>
      <td>Int</td>
      <td>"prediction"</td>
      <td>Predicted cluster center</td>
    </tr>
  </tbody>
</table>

<p><strong>Examples</strong></p>

<div class="codetabs">

<div data-lang="scala">
    <p>Refer to the <a href="api/scala/index.html#org.apache.spark.ml.clustering.KMeans">Scala API docs</a> for more details.</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.clustering.KMeans</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.evaluation.ClusteringEvaluator</span>

<span class="c1">// Loads data.</span>
<span class="k">val</span> <span class="n">dataset</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;libsvm&quot;</span><span class="o">).</span><span class="n">load</span><span class="o">(</span><span class="s">&quot;data/mllib/sample_kmeans_data.txt&quot;</span><span class="o">)</span>

<span class="c1">// Trains a k-means model.</span>
<span class="k">val</span> <span class="n">kmeans</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">KMeans</span><span class="o">().</span><span class="n">setK</span><span class="o">(</span><span class="mi">2</span><span class="o">).</span><span class="n">setSeed</span><span class="o">(</span><span class="mi">1L</span><span class="o">)</span>
<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">dataset</span><span class="o">)</span>

<span class="c1">// Make predictions</span>
<span class="k">val</span> <span class="n">predictions</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dataset</span><span class="o">)</span>

<span class="c1">// Evaluate clustering by computing Silhouette score</span>
<span class="k">val</span> <span class="n">evaluator</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ClusteringEvaluator</span><span class="o">()</span>

<span class="k">val</span> <span class="n">silhouette</span> <span class="k">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">evaluate</span><span class="o">(</span><span class="n">predictions</span><span class="o">)</span>
<span class="n">println</span><span class="o">(</span><span class="s">s&quot;Silhouette with squared euclidean distance = </span><span class="si">$silhouette</span><span class="s">&quot;</span><span class="o">)</span>

<span class="c1">// Shows the result.</span>
<span class="n">println</span><span class="o">(</span><span class="s">&quot;Cluster Centers: &quot;</span><span class="o">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">clusterCenters</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
</pre></div>
    <div><small>Find full example code at "examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala" in the Spark repo.</small></div>
  </div>

<div data-lang="java">
    <p>Refer to the <a href="api/java/org/apache/spark/ml/clustering/KMeans.html">Java API docs</a> for more details.</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">org.apache.spark.ml.clustering.KMeansModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.clustering.KMeans</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.evaluation.ClusteringEvaluator</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vector</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>

<span class="c1">// Loads data.</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataset</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">read</span><span class="o">().</span><span class="na">format</span><span class="o">(</span><span class="s">&quot;libsvm&quot;</span><span class="o">).</span><span class="na">load</span><span class="o">(</span><span class="s">&quot;data/mllib/sample_kmeans_data.txt&quot;</span><span class="o">);</span>

<span class="c1">// Trains a k-means model.</span>
<span class="n">KMeans</span> <span class="n">kmeans</span> <span class="o">=</span> <span class="k">new</span> <span class="n">KMeans</span><span class="o">().</span><span class="na">setK</span><span class="o">(</span><span class="mi">2</span><span class="o">).</span><span class="na">setSeed</span><span class="o">(</span><span class="mi">1L</span><span class="o">);</span>
<span class="n">KMeansModel</span> <span class="n">model</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">dataset</span><span class="o">);</span>

<span class="c1">// Make predictions</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">dataset</span><span class="o">);</span>

<span class="c1">// Evaluate clustering by computing Silhouette score</span>
<span class="n">ClusteringEvaluator</span> <span class="n">evaluator</span> <span class="o">=</span> <span class="k">new</span> <span class="n">ClusteringEvaluator</span><span class="o">();</span>

<span class="kt">double</span> <span class="n">silhouette</span> <span class="o">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="na">evaluate</span><span class="o">(</span><span class="n">predictions</span><span class="o">);</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Silhouette with squared euclidean distance = &quot;</span> <span class="o">+</span> <span class="n">silhouette</span><span class="o">);</span>

<span class="c1">// Shows the result.</span>
<span class="n">Vector</span><span class="o">[]</span> <span class="n">centers</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="na">clusterCenters</span><span class="o">();</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Cluster Centers: &quot;</span><span class="o">);</span>
<span class="k">for</span> <span class="o">(</span><span class="n">Vector</span> <span class="n">center</span><span class="o">:</span> <span class="n">centers</span><span class="o">)</span> <span class="o">{</span>
  <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">center</span><span class="o">);</span>
<span class="o">}</span>
</pre></div>
    <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java" in the Spark repo.</small></div>
  </div>

<div data-lang="python">
    <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.clustering.KMeans">Python API docs</a> for more details.</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.clustering</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.evaluation</span> <span class="kn">import</span> <span class="n">ClusteringEvaluator</span>

<span class="c1"># Loads data.</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;libsvm&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;data/mllib/sample_kmeans_data.txt&quot;</span><span class="p">)</span>

<span class="c1"># Trains a k-means model.</span>
<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">()</span><span class="o">.</span><span class="n">setK</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">setSeed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>

<span class="c1"># Make predictions</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>

<span class="c1"># Evaluate clustering by computing Silhouette score</span>
<span class="n">evaluator</span> <span class="o">=</span> <span class="n">ClusteringEvaluator</span><span class="p">()</span>

<span class="n">silhouette</span> <span class="o">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Silhouette with squared euclidean distance = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">silhouette</span><span class="p">))</span>

<span class="c1"># Shows the result.</span>
<span class="n">centers</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">clusterCenters</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Cluster Centers: &quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">center</span> <span class="ow">in</span> <span class="n">centers</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">center</span><span class="p">)</span>
</pre></div>
    <div><small>Find full example code at "examples/src/main/python/ml/kmeans_example.py" in the Spark repo.</small></div>
  </div>

<div data-lang="r">

    <p>Refer to the <a href="api/R/spark.kmeans.html">R API docs</a> for more details.</p>

    <div class="highlight"><pre><span></span><span class="c1"># Fit a k-means model with spark.kmeans</span>
t <span class="o">&lt;-</span> <span class="kp">as.data.frame</span><span class="p">(</span>Titanic<span class="p">)</span>
training <span class="o">&lt;-</span> createDataFrame<span class="p">(</span><span class="kp">t</span><span class="p">)</span>
df_list <span class="o">&lt;-</span> randomSplit<span class="p">(</span>training<span class="p">,</span> <span class="kt">c</span><span class="p">(</span><span class="m">7</span><span class="p">,</span><span class="m">3</span><span class="p">),</span> <span class="m">2</span><span class="p">)</span>
kmeansDF <span class="o">&lt;-</span> df_list<span class="p">[[</span><span class="m">1</span><span class="p">]]</span>
kmeansTestDF <span class="o">&lt;-</span> df_list<span class="p">[[</span><span class="m">2</span><span class="p">]]</span>
kmeansModel <span class="o">&lt;-</span> spark.kmeans<span class="p">(</span>kmeansDF<span class="p">,</span> <span class="o">~</span> Class <span class="o">+</span> Sex <span class="o">+</span> Age <span class="o">+</span> Freq<span class="p">,</span>
                            k <span class="o">=</span> <span class="m">3</span><span class="p">)</span>

<span class="c1"># Model summary</span>
<span class="kp">summary</span><span class="p">(</span>kmeansModel<span class="p">)</span>

<span class="c1"># Get fitted result from the k-means model</span>
<span class="kp">head</span><span class="p">(</span>fitted<span class="p">(</span>kmeansModel<span class="p">))</span>

<span class="c1"># Prediction</span>
kmeansPredictions <span class="o">&lt;-</span> predict<span class="p">(</span>kmeansModel<span class="p">,</span> kmeansTestDF<span class="p">)</span>
<span class="kp">head</span><span class="p">(</span>kmeansPredictions<span class="p">)</span>
</pre></div>
    <div><small>Find full example code at "examples/src/main/r/ml/kmeans.R" in the Spark repo.</small></div>
  </div>

</div>

<h2 id="latent-dirichlet-allocation-lda">Latent Dirichlet allocation (LDA)</h2>

<p><code>LDA</code> is implemented as an <code>Estimator</code> that supports both <code>EMLDAOptimizer</code> and <code>OnlineLDAOptimizer</code>,
and generates a <code>LDAModel</code> as the base model. Expert users may cast a <code>LDAModel</code> generated by
<code>EMLDAOptimizer</code> to a <code>DistributedLDAModel</code> if needed.</p>

<p><strong>Examples</strong></p>

<div class="codetabs">

<div data-lang="scala">

    <p>Refer to the <a href="api/scala/index.html#org.apache.spark.ml.clustering.LDA">Scala API docs</a> for more details.</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.clustering.LDA</span>

<span class="c1">// Loads data.</span>
<span class="k">val</span> <span class="n">dataset</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;libsvm&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">load</span><span class="o">(</span><span class="s">&quot;data/mllib/sample_lda_libsvm_data.txt&quot;</span><span class="o">)</span>

<span class="c1">// Trains a LDA model.</span>
<span class="k">val</span> <span class="n">lda</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">LDA</span><span class="o">().</span><span class="n">setK</span><span class="o">(</span><span class="mi">10</span><span class="o">).</span><span class="n">setMaxIter</span><span class="o">(</span><span class="mi">10</span><span class="o">)</span>
<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="n">lda</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">dataset</span><span class="o">)</span>

<span class="k">val</span> <span class="n">ll</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">logLikelihood</span><span class="o">(</span><span class="n">dataset</span><span class="o">)</span>
<span class="k">val</span> <span class="n">lp</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">logPerplexity</span><span class="o">(</span><span class="n">dataset</span><span class="o">)</span>
<span class="n">println</span><span class="o">(</span><span class="s">s&quot;The lower bound on the log likelihood of the entire corpus: </span><span class="si">$ll</span><span class="s">&quot;</span><span class="o">)</span>
<span class="n">println</span><span class="o">(</span><span class="s">s&quot;The upper bound on perplexity: </span><span class="si">$lp</span><span class="s">&quot;</span><span class="o">)</span>

<span class="c1">// Describe topics.</span>
<span class="k">val</span> <span class="n">topics</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">describeTopics</span><span class="o">(</span><span class="mi">3</span><span class="o">)</span>
<span class="n">println</span><span class="o">(</span><span class="s">&quot;The topics described by their top-weighted terms:&quot;</span><span class="o">)</span>
<span class="n">topics</span><span class="o">.</span><span class="n">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>

<span class="c1">// Shows the result.</span>
<span class="k">val</span> <span class="n">transformed</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dataset</span><span class="o">)</span>
<span class="n">transformed</span><span class="o">.</span><span class="n">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
</pre></div>
    <div><small>Find full example code at "examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala" in the Spark repo.</small></div>
  </div>

<div data-lang="java">

    <p>Refer to the <a href="api/java/org/apache/spark/ml/clustering/LDA.html">Java API docs</a> for more details.</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">org.apache.spark.ml.clustering.LDA</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.clustering.LDAModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.SparkSession</span><span class="o">;</span>

<span class="c1">// Loads data.</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataset</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">read</span><span class="o">().</span><span class="na">format</span><span class="o">(</span><span class="s">&quot;libsvm&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">load</span><span class="o">(</span><span class="s">&quot;data/mllib/sample_lda_libsvm_data.txt&quot;</span><span class="o">);</span>

<span class="c1">// Trains a LDA model.</span>
<span class="n">LDA</span> <span class="n">lda</span> <span class="o">=</span> <span class="k">new</span> <span class="n">LDA</span><span class="o">().</span><span class="na">setK</span><span class="o">(</span><span class="mi">10</span><span class="o">).</span><span class="na">setMaxIter</span><span class="o">(</span><span class="mi">10</span><span class="o">);</span>
<span class="n">LDAModel</span> <span class="n">model</span> <span class="o">=</span> <span class="n">lda</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">dataset</span><span class="o">);</span>

<span class="kt">double</span> <span class="n">ll</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="na">logLikelihood</span><span class="o">(</span><span class="n">dataset</span><span class="o">);</span>
<span class="kt">double</span> <span class="n">lp</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="na">logPerplexity</span><span class="o">(</span><span class="n">dataset</span><span class="o">);</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;The lower bound on the log likelihood of the entire corpus: &quot;</span> <span class="o">+</span> <span class="n">ll</span><span class="o">);</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;The upper bound on perplexity: &quot;</span> <span class="o">+</span> <span class="n">lp</span><span class="o">);</span>

<span class="c1">// Describe topics.</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">topics</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="na">describeTopics</span><span class="o">(</span><span class="mi">3</span><span class="o">);</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;The topics described by their top-weighted terms:&quot;</span><span class="o">);</span>
<span class="n">topics</span><span class="o">.</span><span class="na">show</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>

<span class="c1">// Shows the result.</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">transformed</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">dataset</span><span class="o">);</span>
<span class="n">transformed</span><span class="o">.</span><span class="na">show</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>
</pre></div>
    <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java" in the Spark repo.</small></div>
  </div>

<div data-lang="python">

    <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.clustering.LDA">Python API docs</a> for more details.</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.clustering</span> <span class="kn">import</span> <span class="n">LDA</span>

<span class="c1"># Loads data.</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;libsvm&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;data/mllib/sample_lda_libsvm_data.txt&quot;</span><span class="p">)</span>

<span class="c1"># Trains a LDA model.</span>
<span class="n">lda</span> <span class="o">=</span> <span class="n">LDA</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">maxIter</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">lda</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>

<span class="n">ll</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">logLikelihood</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">lp</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">logPerplexity</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;The lower bound on the log likelihood of the entire corpus: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">ll</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;The upper bound on perplexity: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">lp</span><span class="p">))</span>

<span class="c1"># Describe topics.</span>
<span class="n">topics</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">describeTopics</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;The topics described by their top-weighted terms:&quot;</span><span class="p">)</span>
<span class="n">topics</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># Shows the result</span>
<span class="n">transformed</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">transformed</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
    <div><small>Find full example code at "examples/src/main/python/ml/lda_example.py" in the Spark repo.</small></div>
  </div>

<div data-lang="r">

    <p>Refer to the <a href="api/R/spark.lda.html">R API docs</a> for more details.</p>

    <div class="highlight"><pre><span></span><span class="c1"># Load training data</span>
df <span class="o">&lt;-</span> read.df<span class="p">(</span><span class="s">&quot;data/mllib/sample_lda_libsvm_data.txt&quot;</span><span class="p">,</span> <span class="kn">source</span> <span class="o">=</span> <span class="s">&quot;libsvm&quot;</span><span class="p">)</span>
training <span class="o">&lt;-</span> df
test <span class="o">&lt;-</span> df

<span class="c1"># Fit a latent dirichlet allocation model with spark.lda</span>
model <span class="o">&lt;-</span> spark.lda<span class="p">(</span>training<span class="p">,</span> k <span class="o">=</span> <span class="m">10</span><span class="p">,</span> maxIter <span class="o">=</span> <span class="m">10</span><span class="p">)</span>

<span class="c1"># Model summary</span>
<span class="kp">summary</span><span class="p">(</span>model<span class="p">)</span>

<span class="c1"># Posterior probabilities</span>
posterior <span class="o">&lt;-</span> spark.posterior<span class="p">(</span>model<span class="p">,</span> test<span class="p">)</span>
<span class="kp">head</span><span class="p">(</span>posterior<span class="p">)</span>

<span class="c1"># The log perplexity of the LDA model</span>
logPerplexity <span class="o">&lt;-</span> spark.perplexity<span class="p">(</span>model<span class="p">,</span> test<span class="p">)</span>
<span class="kp">print</span><span class="p">(</span><span class="kp">paste0</span><span class="p">(</span><span class="s">&quot;The upper bound bound on perplexity: &quot;</span><span class="p">,</span> logPerplexity<span class="p">))</span>
</pre></div>
    <div><small>Find full example code at "examples/src/main/r/ml/lda.R" in the Spark repo.</small></div>
  </div>

</div>

<h2 id="bisecting-k-means">Bisecting k-means</h2>

<p>Bisecting k-means is a kind of <a href="https://en.wikipedia.org/wiki/Hierarchical_clustering">hierarchical clustering</a> using a
divisive (or &#8220;top-down&#8221;) approach: all observations start in one cluster, and splits are performed recursively as one
moves down the hierarchy.</p>

<p>Bisecting K-means can often be much faster than regular K-means, but it will generally produce a different clustering.</p>

<p><code>BisectingKMeans</code> is implemented as an <code>Estimator</code> and generates a <code>BisectingKMeansModel</code> as the base model.</p>

<p><strong>Examples</strong></p>

<div class="codetabs">

<div data-lang="scala">
    <p>Refer to the <a href="api/scala/index.html#org.apache.spark.ml.clustering.BisectingKMeans">Scala API docs</a> for more details.</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.clustering.BisectingKMeans</span>
<span class="k">import</span> <span class="nn">org.apache.spark.ml.evaluation.ClusteringEvaluator</span>

<span class="c1">// Loads data.</span>
<span class="k">val</span> <span class="n">dataset</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;libsvm&quot;</span><span class="o">).</span><span class="n">load</span><span class="o">(</span><span class="s">&quot;data/mllib/sample_kmeans_data.txt&quot;</span><span class="o">)</span>

<span class="c1">// Trains a bisecting k-means model.</span>
<span class="k">val</span> <span class="n">bkm</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">BisectingKMeans</span><span class="o">().</span><span class="n">setK</span><span class="o">(</span><span class="mi">2</span><span class="o">).</span><span class="n">setSeed</span><span class="o">(</span><span class="mi">1</span><span class="o">)</span>
<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="n">bkm</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">dataset</span><span class="o">)</span>

<span class="c1">// Make predictions</span>
<span class="k">val</span> <span class="n">predictions</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="o">(</span><span class="n">dataset</span><span class="o">)</span>

<span class="c1">// Evaluate clustering by computing Silhouette score</span>
<span class="k">val</span> <span class="n">evaluator</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ClusteringEvaluator</span><span class="o">()</span>

<span class="k">val</span> <span class="n">silhouette</span> <span class="k">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">evaluate</span><span class="o">(</span><span class="n">predictions</span><span class="o">)</span>
<span class="n">println</span><span class="o">(</span><span class="s">s&quot;Silhouette with squared euclidean distance = </span><span class="si">$silhouette</span><span class="s">&quot;</span><span class="o">)</span>

<span class="c1">// Shows the result.</span>
<span class="n">println</span><span class="o">(</span><span class="s">&quot;Cluster Centers: &quot;</span><span class="o">)</span>
<span class="k">val</span> <span class="n">centers</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">clusterCenters</span>
<span class="n">centers</span><span class="o">.</span><span class="n">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
</pre></div>
    <div><small>Find full example code at "examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala" in the Spark repo.</small></div>
  </div>

<div data-lang="java">
    <p>Refer to the <a href="api/java/org/apache/spark/ml/clustering/BisectingKMeans.html">Java API docs</a> for more details.</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">org.apache.spark.ml.clustering.BisectingKMeans</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.clustering.BisectingKMeansModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.evaluation.ClusteringEvaluator</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.linalg.Vector</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>

<span class="c1">// Loads data.</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataset</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">read</span><span class="o">().</span><span class="na">format</span><span class="o">(</span><span class="s">&quot;libsvm&quot;</span><span class="o">).</span><span class="na">load</span><span class="o">(</span><span class="s">&quot;data/mllib/sample_kmeans_data.txt&quot;</span><span class="o">);</span>

<span class="c1">// Trains a bisecting k-means model.</span>
<span class="n">BisectingKMeans</span> <span class="n">bkm</span> <span class="o">=</span> <span class="k">new</span> <span class="n">BisectingKMeans</span><span class="o">().</span><span class="na">setK</span><span class="o">(</span><span class="mi">2</span><span class="o">).</span><span class="na">setSeed</span><span class="o">(</span><span class="mi">1</span><span class="o">);</span>
<span class="n">BisectingKMeansModel</span> <span class="n">model</span> <span class="o">=</span> <span class="n">bkm</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">dataset</span><span class="o">);</span>

<span class="c1">// Make predictions</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="na">transform</span><span class="o">(</span><span class="n">dataset</span><span class="o">);</span>

<span class="c1">// Evaluate clustering by computing Silhouette score</span>
<span class="n">ClusteringEvaluator</span> <span class="n">evaluator</span> <span class="o">=</span> <span class="k">new</span> <span class="n">ClusteringEvaluator</span><span class="o">();</span>

<span class="kt">double</span> <span class="n">silhouette</span> <span class="o">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="na">evaluate</span><span class="o">(</span><span class="n">predictions</span><span class="o">);</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Silhouette with squared euclidean distance = &quot;</span> <span class="o">+</span> <span class="n">silhouette</span><span class="o">);</span>

<span class="c1">// Shows the result.</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Cluster Centers: &quot;</span><span class="o">);</span>
<span class="n">Vector</span><span class="o">[]</span> <span class="n">centers</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="na">clusterCenters</span><span class="o">();</span>
<span class="k">for</span> <span class="o">(</span><span class="n">Vector</span> <span class="n">center</span> <span class="o">:</span> <span class="n">centers</span><span class="o">)</span> <span class="o">{</span>
  <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">center</span><span class="o">);</span>
<span class="o">}</span>
</pre></div>
    <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java" in the Spark repo.</small></div>
  </div>

<div data-lang="python">
    <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.clustering.BisectingKMeans">Python API docs</a> for more details.</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.clustering</span> <span class="kn">import</span> <span class="n">BisectingKMeans</span>
<span class="kn">from</span> <span class="nn">pyspark.ml.evaluation</span> <span class="kn">import</span> <span class="n">ClusteringEvaluator</span>

<span class="c1"># Loads data.</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;libsvm&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;data/mllib/sample_kmeans_data.txt&quot;</span><span class="p">)</span>

<span class="c1"># Trains a bisecting k-means model.</span>
<span class="n">bkm</span> <span class="o">=</span> <span class="n">BisectingKMeans</span><span class="p">()</span><span class="o">.</span><span class="n">setK</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">setSeed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">bkm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>

<span class="c1"># Make predictions</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>

<span class="c1"># Evaluate clustering by computing Silhouette score</span>
<span class="n">evaluator</span> <span class="o">=</span> <span class="n">ClusteringEvaluator</span><span class="p">()</span>

<span class="n">silhouette</span> <span class="o">=</span> <span class="n">evaluator</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Silhouette with squared euclidean distance = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">silhouette</span><span class="p">))</span>

<span class="c1"># Shows the result.</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Cluster Centers: &quot;</span><span class="p">)</span>
<span class="n">centers</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">clusterCenters</span><span class="p">()</span>
<span class="k">for</span> <span class="n">center</span> <span class="ow">in</span> <span class="n">centers</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">center</span><span class="p">)</span>
</pre></div>
    <div><small>Find full example code at "examples/src/main/python/ml/bisecting_k_means_example.py" in the Spark repo.</small></div>
  </div>

<div data-lang="r">

    <p>Refer to the <a href="api/R/spark.bisectingKmeans.html">R API docs</a> for more details.</p>

    <div class="highlight"><pre><span></span>t <span class="o">&lt;-</span> <span class="kp">as.data.frame</span><span class="p">(</span>Titanic<span class="p">)</span>
training <span class="o">&lt;-</span> createDataFrame<span class="p">(</span><span class="kp">t</span><span class="p">)</span>

<span class="c1"># Fit bisecting k-means model with four centers</span>
model <span class="o">&lt;-</span> spark.bisectingKmeans<span class="p">(</span>training<span class="p">,</span> Class <span class="o">~</span> Survived<span class="p">,</span> k <span class="o">=</span> <span class="m">4</span><span class="p">)</span>

<span class="c1"># get fitted result from a bisecting k-means model</span>
fitted.model <span class="o">&lt;-</span> fitted<span class="p">(</span>model<span class="p">,</span> <span class="s">&quot;centers&quot;</span><span class="p">)</span>

<span class="c1"># Model summary</span>
<span class="kp">head</span><span class="p">(</span><span class="kp">summary</span><span class="p">(</span>fitted.model<span class="p">))</span>

<span class="c1"># fitted values on training data</span>
fitted <span class="o">&lt;-</span> predict<span class="p">(</span>model<span class="p">,</span> training<span class="p">)</span>
<span class="kp">head</span><span class="p">(</span>select<span class="p">(</span>fitted<span class="p">,</span> <span class="s">&quot;Class&quot;</span><span class="p">,</span> <span class="s">&quot;prediction&quot;</span><span class="p">))</span>
</pre></div>
    <div><small>Find full example code at "examples/src/main/r/ml/bisectingKmeans.R" in the Spark repo.</small></div>
  </div>
</div>

<h2 id="gaussian-mixture-model-gmm">Gaussian Mixture Model (GMM)</h2>

<p>A <a href="http://en.wikipedia.org/wiki/Mixture_model#Multivariate_Gaussian_mixture_model">Gaussian Mixture Model</a>
represents a composite distribution whereby points are drawn from one of <em>k</em> Gaussian sub-distributions,
each with its own probability. The <code>spark.ml</code> implementation uses the
<a href="http://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm">expectation-maximization</a>
algorithm to induce the maximum-likelihood model given a set of samples.</p>

<p><code>GaussianMixture</code> is implemented as an <code>Estimator</code> and generates a <code>GaussianMixtureModel</code> as the base
model.</p>

<h3 id="input-columns-1">Input Columns</h3>

<table class="table">
  <thead>
    <tr>
      <th align="left">Param name</th>
      <th align="left">Type(s)</th>
      <th align="left">Default</th>
      <th align="left">Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>featuresCol</td>
      <td>Vector</td>
      <td>"features"</td>
      <td>Feature vector</td>
    </tr>
  </tbody>
</table>

<h3 id="output-columns-1">Output Columns</h3>

<table class="table">
  <thead>
    <tr>
      <th align="left">Param name</th>
      <th align="left">Type(s)</th>
      <th align="left">Default</th>
      <th align="left">Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>predictionCol</td>
      <td>Int</td>
      <td>"prediction"</td>
      <td>Predicted cluster center</td>
    </tr>
    <tr>
      <td>probabilityCol</td>
      <td>Vector</td>
      <td>"probability"</td>
      <td>Probability of each cluster</td>
    </tr>
  </tbody>
</table>

<p><strong>Examples</strong></p>

<div class="codetabs">

<div data-lang="scala">
    <p>Refer to the <a href="api/scala/index.html#org.apache.spark.ml.clustering.GaussianMixture">Scala API docs</a> for more details.</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.clustering.GaussianMixture</span>

<span class="c1">// Loads data</span>
<span class="k">val</span> <span class="n">dataset</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="o">(</span><span class="s">&quot;libsvm&quot;</span><span class="o">).</span><span class="n">load</span><span class="o">(</span><span class="s">&quot;data/mllib/sample_kmeans_data.txt&quot;</span><span class="o">)</span>

<span class="c1">// Trains Gaussian Mixture Model</span>
<span class="k">val</span> <span class="n">gmm</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">GaussianMixture</span><span class="o">()</span>
  <span class="o">.</span><span class="n">setK</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="n">gmm</span><span class="o">.</span><span class="n">fit</span><span class="o">(</span><span class="n">dataset</span><span class="o">)</span>

<span class="c1">// output parameters of mixture model model</span>
<span class="k">for</span> <span class="o">(</span><span class="n">i</span> <span class="k">&lt;-</span> <span class="mi">0</span> <span class="n">until</span> <span class="n">model</span><span class="o">.</span><span class="n">getK</span><span class="o">)</span> <span class="o">{</span>
  <span class="n">println</span><span class="o">(</span><span class="s">s&quot;Gaussian </span><span class="si">$i</span><span class="s">:\nweight=</span><span class="si">${</span><span class="n">model</span><span class="o">.</span><span class="n">weights</span><span class="o">(</span><span class="n">i</span><span class="o">)</span><span class="si">}</span><span class="s">\n&quot;</span> <span class="o">+</span>
      <span class="s">s&quot;mu=</span><span class="si">${</span><span class="n">model</span><span class="o">.</span><span class="n">gaussians</span><span class="o">(</span><span class="n">i</span><span class="o">).</span><span class="n">mean</span><span class="si">}</span><span class="s">\nsigma=\n</span><span class="si">${</span><span class="n">model</span><span class="o">.</span><span class="n">gaussians</span><span class="o">(</span><span class="n">i</span><span class="o">).</span><span class="n">cov</span><span class="si">}</span><span class="s">\n&quot;</span><span class="o">)</span>
<span class="o">}</span>
</pre></div>
    <div><small>Find full example code at "examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala" in the Spark repo.</small></div>
  </div>

<div data-lang="java">
    <p>Refer to the <a href="api/java/org/apache/spark/ml/clustering/GaussianMixture.html">Java API docs</a> for more details.</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">org.apache.spark.ml.clustering.GaussianMixture</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.ml.clustering.GaussianMixtureModel</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>

<span class="c1">// Loads data</span>
<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">dataset</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">read</span><span class="o">().</span><span class="na">format</span><span class="o">(</span><span class="s">&quot;libsvm&quot;</span><span class="o">).</span><span class="na">load</span><span class="o">(</span><span class="s">&quot;data/mllib/sample_kmeans_data.txt&quot;</span><span class="o">);</span>

<span class="c1">// Trains a GaussianMixture model</span>
<span class="n">GaussianMixture</span> <span class="n">gmm</span> <span class="o">=</span> <span class="k">new</span> <span class="n">GaussianMixture</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setK</span><span class="o">(</span><span class="mi">2</span><span class="o">);</span>
<span class="n">GaussianMixtureModel</span> <span class="n">model</span> <span class="o">=</span> <span class="n">gmm</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">dataset</span><span class="o">);</span>

<span class="c1">// Output the parameters of the mixture model</span>
<span class="k">for</span> <span class="o">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">model</span><span class="o">.</span><span class="na">getK</span><span class="o">();</span> <span class="n">i</span><span class="o">++)</span> <span class="o">{</span>
  <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">printf</span><span class="o">(</span><span class="s">&quot;Gaussian %d:\nweight=%f\nmu=%s\nsigma=\n%s\n\n&quot;</span><span class="o">,</span>
          <span class="n">i</span><span class="o">,</span> <span class="n">model</span><span class="o">.</span><span class="na">weights</span><span class="o">()[</span><span class="n">i</span><span class="o">],</span> <span class="n">model</span><span class="o">.</span><span class="na">gaussians</span><span class="o">()[</span><span class="n">i</span><span class="o">].</span><span class="na">mean</span><span class="o">(),</span> <span class="n">model</span><span class="o">.</span><span class="na">gaussians</span><span class="o">()[</span><span class="n">i</span><span class="o">].</span><span class="na">cov</span><span class="o">());</span>
<span class="o">}</span>
</pre></div>
    <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java" in the Spark repo.</small></div>
  </div>

<div data-lang="python">
    <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.clustering.GaussianMixture">Python API docs</a> for more details.</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.clustering</span> <span class="kn">import</span> <span class="n">GaussianMixture</span>

<span class="c1"># loads data</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;libsvm&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;data/mllib/sample_kmeans_data.txt&quot;</span><span class="p">)</span>

<span class="n">gmm</span> <span class="o">=</span> <span class="n">GaussianMixture</span><span class="p">()</span><span class="o">.</span><span class="n">setK</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">setSeed</span><span class="p">(</span><span class="mi">538009335</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">gmm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Gaussians shown as a DataFrame: &quot;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">gaussiansDF</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">truncate</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
    <div><small>Find full example code at "examples/src/main/python/ml/gaussian_mixture_example.py" in the Spark repo.</small></div>
  </div>

<div data-lang="r">

    <p>Refer to the <a href="api/R/spark.gaussianMixture.html">R API docs</a> for more details.</p>

    <div class="highlight"><pre><span></span><span class="c1"># Load training data</span>
df <span class="o">&lt;-</span> read.df<span class="p">(</span><span class="s">&quot;data/mllib/sample_kmeans_data.txt&quot;</span><span class="p">,</span> <span class="kn">source</span> <span class="o">=</span> <span class="s">&quot;libsvm&quot;</span><span class="p">)</span>
training <span class="o">&lt;-</span> df
test <span class="o">&lt;-</span> df

<span class="c1"># Fit a gaussian mixture clustering model with spark.gaussianMixture</span>
model <span class="o">&lt;-</span> spark.gaussianMixture<span class="p">(</span>training<span class="p">,</span> <span class="o">~</span> features<span class="p">,</span> k <span class="o">=</span> <span class="m">2</span><span class="p">)</span>

<span class="c1"># Model summary</span>
<span class="kp">summary</span><span class="p">(</span>model<span class="p">)</span>

<span class="c1"># Prediction</span>
predictions <span class="o">&lt;-</span> predict<span class="p">(</span>model<span class="p">,</span> test<span class="p">)</span>
<span class="kp">head</span><span class="p">(</span>predictions<span class="p">)</span>
</pre></div>
    <div><small>Find full example code at "examples/src/main/r/ml/gaussianMixture.R" in the Spark repo.</small></div>
  </div>

</div>

<h2 id="power-iteration-clustering-pic">Power Iteration Clustering (PIC)</h2>

<p>Power Iteration Clustering (PIC) is  a scalable graph clustering algorithm
developed by <a href="http://www.cs.cmu.edu/~frank/papers/icml2010-pic-final.pdf">Lin and Cohen</a>.
From the abstract: PIC finds a very low-dimensional embedding of a dataset
using truncated power iteration on a normalized pair-wise similarity matrix of the data.</p>

<p><code>spark.ml</code>&#8217;s PowerIterationClustering implementation takes the following parameters:</p>

<ul>
  <li><code>k</code>: the number of clusters to create</li>
  <li><code>initMode</code>: param for the initialization algorithm</li>
  <li><code>maxIter</code>: param for maximum number of iterations</li>
  <li><code>srcCol</code>: param for the name of the input column for source vertex IDs</li>
  <li><code>dstCol</code>: name of the input column for destination vertex IDs</li>
  <li><code>weightCol</code>: Param for weight column name</li>
</ul>

<p><strong>Examples</strong></p>

<div class="codetabs">

<div data-lang="scala">
    <p>Refer to the <a href="api/scala/index.html#org.apache.spark.ml.clustering.PowerIterationClustering">Scala API docs</a> for more details.</p>

    <div class="highlight"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.ml.clustering.PowerIterationClustering</span>

<span class="k">val</span> <span class="n">dataset</span> <span class="k">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="o">(</span><span class="nc">Seq</span><span class="o">(</span>
  <span class="o">(</span><span class="mi">0L</span><span class="o">,</span> <span class="mi">1L</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">0L</span><span class="o">,</span> <span class="mi">2L</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">1L</span><span class="o">,</span> <span class="mi">2L</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">3L</span><span class="o">,</span> <span class="mi">4L</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="o">(</span><span class="mi">4L</span><span class="o">,</span> <span class="mi">0L</span><span class="o">,</span> <span class="mf">0.1</span><span class="o">)</span>
<span class="o">)).</span><span class="n">toDF</span><span class="o">(</span><span class="s">&quot;src&quot;</span><span class="o">,</span> <span class="s">&quot;dst&quot;</span><span class="o">,</span> <span class="s">&quot;weight&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">model</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">PowerIterationClustering</span><span class="o">().</span>
  <span class="n">setK</span><span class="o">(</span><span class="mi">2</span><span class="o">).</span>
  <span class="n">setMaxIter</span><span class="o">(</span><span class="mi">20</span><span class="o">).</span>
  <span class="n">setInitMode</span><span class="o">(</span><span class="s">&quot;degree&quot;</span><span class="o">).</span>
  <span class="n">setWeightCol</span><span class="o">(</span><span class="s">&quot;weight&quot;</span><span class="o">)</span>

<span class="k">val</span> <span class="n">prediction</span> <span class="k">=</span> <span class="n">model</span><span class="o">.</span><span class="n">assignClusters</span><span class="o">(</span><span class="n">dataset</span><span class="o">).</span><span class="n">select</span><span class="o">(</span><span class="s">&quot;id&quot;</span><span class="o">,</span> <span class="s">&quot;cluster&quot;</span><span class="o">)</span>

<span class="c1">//  Shows the cluster assignment</span>
<span class="n">prediction</span><span class="o">.</span><span class="n">show</span><span class="o">(</span><span class="kc">false</span><span class="o">)</span>
</pre></div>
    <div><small>Find full example code at "examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala" in the Spark repo.</small></div>
  </div>

<div data-lang="java">
    <p>Refer to the <a href="api/java/org/apache/spark/ml/clustering/PowerIterationClustering.html">Java API docs</a> for more details.</p>

    <div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">java.util.Arrays</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.util.List</span><span class="o">;</span>

<span class="kn">import</span> <span class="nn">org.apache.spark.ml.clustering.PowerIterationClustering</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Dataset</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.Row</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.RowFactory</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.SparkSession</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.DataTypes</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.Metadata</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructField</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.types.StructType</span><span class="o">;</span>

<span class="n">List</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">0</span><span class="n">L</span><span class="o">,</span> <span class="mi">1L</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">0</span><span class="n">L</span><span class="o">,</span> <span class="mi">2L</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">1L</span><span class="o">,</span> <span class="mi">2L</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">3L</span><span class="o">,</span> <span class="mi">4L</span><span class="o">,</span> <span class="mf">1.0</span><span class="o">),</span>
  <span class="n">RowFactory</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="mi">4L</span><span class="o">,</span> <span class="mi">0</span><span class="n">L</span><span class="o">,</span> <span class="mf">0.1</span><span class="o">)</span>
<span class="o">);</span>

<span class="n">StructType</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">StructType</span><span class="o">(</span><span class="k">new</span> <span class="n">StructField</span><span class="o">[]{</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;src&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">LongType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;dst&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">LongType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">()),</span>
  <span class="k">new</span> <span class="n">StructField</span><span class="o">(</span><span class="s">&quot;weight&quot;</span><span class="o">,</span> <span class="n">DataTypes</span><span class="o">.</span><span class="na">DoubleType</span><span class="o">,</span> <span class="kc">false</span><span class="o">,</span> <span class="n">Metadata</span><span class="o">.</span><span class="na">empty</span><span class="o">())</span>
<span class="o">});</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="na">createDataFrame</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="n">schema</span><span class="o">);</span>

<span class="n">PowerIterationClustering</span> <span class="n">model</span> <span class="o">=</span> <span class="k">new</span> <span class="n">PowerIterationClustering</span><span class="o">()</span>
  <span class="o">.</span><span class="na">setK</span><span class="o">(</span><span class="mi">2</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setMaxIter</span><span class="o">(</span><span class="mi">10</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setInitMode</span><span class="o">(</span><span class="s">&quot;degree&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">setWeightCol</span><span class="o">(</span><span class="s">&quot;weight&quot;</span><span class="o">);</span>

<span class="n">Dataset</span><span class="o">&lt;</span><span class="n">Row</span><span class="o">&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="na">assignClusters</span><span class="o">(</span><span class="n">df</span><span class="o">);</span>
<span class="n">result</span><span class="o">.</span><span class="na">show</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span>
</pre></div>
    <div><small>Find full example code at "examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java" in the Spark repo.</small></div>
  </div>

<div data-lang="python">
    <p>Refer to the <a href="api/python/pyspark.ml.html#pyspark.ml.clustering.PowerIterationClustering">Python API docs</a> for more details.</p>

    <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.ml.clustering</span> <span class="kn">import</span> <span class="n">PowerIterationClustering</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
    <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
    <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="p">],</span> <span class="p">[</span><span class="s2">&quot;src&quot;</span><span class="p">,</span> <span class="s2">&quot;dst&quot;</span><span class="p">,</span> <span class="s2">&quot;weight&quot;</span><span class="p">])</span>

<span class="n">pic</span> <span class="o">=</span> <span class="n">PowerIterationClustering</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">maxIter</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">initMode</span><span class="o">=</span><span class="s2">&quot;degree&quot;</span><span class="p">,</span> <span class="n">weightCol</span><span class="o">=</span><span class="s2">&quot;weight&quot;</span><span class="p">)</span>

<span class="c1"># Shows the cluster assignment</span>
<span class="n">pic</span><span class="o">.</span><span class="n">assignClusters</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
    <div><small>Find full example code at "examples/src/main/python/ml/power_iteration_clustering_example.py" in the Spark repo.</small></div>
  </div>

<div data-lang="r">

    <p>Refer to the <a href="api/R/spark.powerIterationClustering.html">R API docs</a> for more details.</p>

    <div class="highlight"><pre><span></span>df <span class="o">&lt;-</span> createDataFrame<span class="p">(</span><span class="kt">list</span><span class="p">(</span><span class="kt">list</span><span class="p">(</span><span class="m">0L</span><span class="p">,</span> <span class="m">1L</span><span class="p">,</span> <span class="m">1.0</span><span class="p">),</span> <span class="kt">list</span><span class="p">(</span><span class="m">0L</span><span class="p">,</span> <span class="m">2L</span><span class="p">,</span> <span class="m">1.0</span><span class="p">),</span>
                           <span class="kt">list</span><span class="p">(</span><span class="m">1L</span><span class="p">,</span> <span class="m">2L</span><span class="p">,</span> <span class="m">1.0</span><span class="p">),</span> <span class="kt">list</span><span class="p">(</span><span class="m">3L</span><span class="p">,</span> <span class="m">4L</span><span class="p">,</span> <span class="m">1.0</span><span class="p">),</span>
                           <span class="kt">list</span><span class="p">(</span><span class="m">4L</span><span class="p">,</span> <span class="m">0L</span><span class="p">,</span> <span class="m">0.1</span><span class="p">)),</span>
                      schema <span class="o">=</span> <span class="kt">c</span><span class="p">(</span><span class="s">&quot;src&quot;</span><span class="p">,</span> <span class="s">&quot;dst&quot;</span><span class="p">,</span> <span class="s">&quot;weight&quot;</span><span class="p">))</span>
<span class="c1"># assign clusters</span>
clusters <span class="o">&lt;-</span> spark.assignClusters<span class="p">(</span>df<span class="p">,</span> k <span class="o">=</span> <span class="m">2L</span><span class="p">,</span> maxIter <span class="o">=</span> <span class="m">20L</span><span class="p">,</span>
                                 initMode <span class="o">=</span> <span class="s">&quot;degree&quot;</span><span class="p">,</span> weightCol <span class="o">=</span> <span class="s">&quot;weight&quot;</span><span class="p">)</span>

showDF<span class="p">(</span>arrange<span class="p">(</span>clusters<span class="p">,</span> clusters<span class="o">$</span>id<span class="p">))</span>
</pre></div>
    <div><small>Find full example code at "examples/src/main/r/ml/powerIterationClustering.R" in the Spark repo.</small></div>
  </div>

</div>
:ET