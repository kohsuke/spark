== Parsed Logical Plan ==
'GlobalLimit 100
+- 'LocalLimit 100
   +- 'Sort ['dt.d_year ASC NULLS FIRST, 'ext_price DESC NULLS LAST, 'brand_id ASC NULLS FIRST], true
      +- 'Aggregate ['dt.d_year, 'item.i_brand, 'item.i_brand_id], ['dt.d_year, 'item.i_brand_id AS brand_id#1, 'item.i_brand AS brand#2, 'sum('ss_ext_sales_price) AS ext_price#3]
         +- 'Filter (((('dt.d_date_sk = 'store_sales.ss_sold_date_sk) AND ('store_sales.ss_item_sk = 'item.i_item_sk)) AND ('item.i_manager_id = 1)) AND ((('dt.d_moy = 12) AND ('dt.d_year = 1998)) AND (('ss_sold_date_sk >= 2451149) AND ('ss_sold_date_sk <= 2451179))))
            +- 'Join Inner
               :- 'Join Inner
               :  :- 'SubqueryAlias dt
               :  :  +- 'UnresolvedRelation [date_dim]
               :  +- 'UnresolvedRelation [store_sales]
               +- 'UnresolvedRelation [item]

== Analyzed Logical Plan ==
d_year: int, brand_id: int, brand: string, ext_price: decimal(17,2)
GlobalLimit 100
+- LocalLimit 100
   +- Sort [d_year#4 ASC NULLS FIRST, ext_price#3 DESC NULLS LAST, brand_id#1 ASC NULLS FIRST], true
      +- Aggregate [d_year#4, i_brand#5, i_brand_id#6], [d_year#4, i_brand_id#6 AS brand_id#1, i_brand#5 AS brand#2, sum(ss_ext_sales_price#7) AS ext_price#3]
         +- Filter ((((d_date_sk#8 = ss_sold_date_sk#9) AND (ss_item_sk#10 = i_item_sk#11)) AND (i_manager_id#12 = 1)) AND (((d_moy#13 = 12) AND (d_year#4 = 1998)) AND ((ss_sold_date_sk#9 >= 2451149) AND (ss_sold_date_sk#9 <= 2451179))))
            +- Join Inner
               :- Join Inner
               :  :- SubqueryAlias dt
               :  :  +- SubqueryAlias spark_catalog.default.date_dim
               :  :     +- Relation[d_date_sk#8,d_date_id#14,d_date#15,d_month_seq#16,d_week_seq#17,d_quarter_seq#18,d_year#4,d_dow#19,d_moy#13,d_dom#20,d_qoy#21,d_fy_year#22,d_fy_quarter_seq#23,d_fy_week_seq#24,d_day_name#25,d_quarter_name#26,d_holiday#27,d_weekend#28,d_following_holiday#29,d_first_dom#30,d_last_dom#31,d_same_day_ly#32,d_same_day_lq#33,d_current_day#34,... 4 more fields] parquet
               :  +- SubqueryAlias spark_catalog.default.store_sales
               :     +- Relation[ss_sold_date_sk#9,ss_sold_time_sk#35,ss_item_sk#10,ss_customer_sk#36,ss_cdemo_sk#37,ss_hdemo_sk#38,ss_addr_sk#39,ss_store_sk#40,ss_promo_sk#41,ss_ticket_number#42,ss_quantity#43,ss_wholesale_cost#44,ss_list_price#45,ss_sales_price#46,ss_ext_discount_amt#47,ss_ext_sales_price#7,ss_ext_wholesale_cost#48,ss_ext_list_price#49,ss_ext_tax#50,ss_coupon_amt#51,ss_net_paid#52,ss_net_paid_inc_tax#53,ss_net_profit#54] parquet
               +- SubqueryAlias spark_catalog.default.item
                  +- Relation[i_item_sk#11,i_item_id#55,i_rec_start_date#56,i_rec_end_date#57,i_item_desc#58,i_current_price#59,i_wholesale_cost#60,i_brand_id#6,i_brand#5,i_class_id#61,i_class#62,i_category_id#63,i_category#64,i_manufact_id#65,i_manufact#66,i_size#67,i_formulation#68,i_color#69,i_units#70,i_container#71,i_manager_id#12,i_product_name#72] parquet

== Optimized Logical Plan ==
GlobalLimit 100
+- LocalLimit 100
   +- Sort [d_year#4 ASC NULLS FIRST, ext_price#3 DESC NULLS LAST, brand_id#1 ASC NULLS FIRST], true
      +- Aggregate [d_year#4, i_brand#5, i_brand_id#6], [d_year#4, i_brand_id#6 AS brand_id#1, i_brand#5 AS brand#2, MakeDecimal(sum(UnscaledValue(ss_ext_sales_price#7)),17,2) AS ext_price#3]
         +- Project [d_year#4, ss_ext_sales_price#7, i_brand_id#6, i_brand#5]
            +- Join Inner, (ss_item_sk#10 = i_item_sk#11)
               :- Project [d_year#4, ss_item_sk#10, ss_ext_sales_price#7]
               :  +- Join Inner, (d_date_sk#8 = ss_sold_date_sk#9)
               :     :- Project [d_date_sk#8, d_year#4]
               :     :  +- Filter ((((((isnotnull(d_moy#13) AND isnotnull(d_year#4)) AND (d_moy#13 = 12)) AND (d_year#4 = 1998)) AND (d_date_sk#8 <= 2451179)) AND (d_date_sk#8 >= 2451149)) AND isnotnull(d_date_sk#8))
               :     :     +- Relation[d_date_sk#8,d_date_id#14,d_date#15,d_month_seq#16,d_week_seq#17,d_quarter_seq#18,d_year#4,d_dow#19,d_moy#13,d_dom#20,d_qoy#21,d_fy_year#22,d_fy_quarter_seq#23,d_fy_week_seq#24,d_day_name#25,d_quarter_name#26,d_holiday#27,d_weekend#28,d_following_holiday#29,d_first_dom#30,d_last_dom#31,d_same_day_ly#32,d_same_day_lq#33,d_current_day#34,... 4 more fields] parquet
               :     +- Project [ss_sold_date_sk#9, ss_item_sk#10, ss_ext_sales_price#7]
               :        +- Filter (((isnotnull(ss_sold_date_sk#9) AND (ss_sold_date_sk#9 >= 2451149)) AND (ss_sold_date_sk#9 <= 2451179)) AND isnotnull(ss_item_sk#10))
               :           +- Relation[ss_sold_date_sk#9,ss_sold_time_sk#35,ss_item_sk#10,ss_customer_sk#36,ss_cdemo_sk#37,ss_hdemo_sk#38,ss_addr_sk#39,ss_store_sk#40,ss_promo_sk#41,ss_ticket_number#42,ss_quantity#43,ss_wholesale_cost#44,ss_list_price#45,ss_sales_price#46,ss_ext_discount_amt#47,ss_ext_sales_price#7,ss_ext_wholesale_cost#48,ss_ext_list_price#49,ss_ext_tax#50,ss_coupon_amt#51,ss_net_paid#52,ss_net_paid_inc_tax#53,ss_net_profit#54] parquet
               +- Project [i_item_sk#11, i_brand_id#6, i_brand#5]
                  +- Filter ((isnotnull(i_manager_id#12) AND (i_manager_id#12 = 1)) AND isnotnull(i_item_sk#11))
                     +- Relation[i_item_sk#11,i_item_id#55,i_rec_start_date#56,i_rec_end_date#57,i_item_desc#58,i_current_price#59,i_wholesale_cost#60,i_brand_id#6,i_brand#5,i_class_id#61,i_class#62,i_category_id#63,i_category#64,i_manufact_id#65,i_manufact#66,i_size#67,i_formulation#68,i_color#69,i_units#70,i_container#71,i_manager_id#12,i_product_name#72] parquet

== Physical Plan ==
TakeOrderedAndProject(limit=100, orderBy=[d_year#4 ASC NULLS FIRST,ext_price#3 DESC NULLS LAST,brand_id#1 ASC NULLS FIRST], output=[d_year#4,brand_id#1,brand#2,ext_price#3])
+- *(4) HashAggregate(keys=[d_year#4, i_brand#5, i_brand_id#6], functions=[sum(UnscaledValue(ss_ext_sales_price#7))], output=[d_year#4, brand_id#1, brand#2, ext_price#3])
   +- Exchange hashpartitioning(d_year#4, i_brand#5, i_brand_id#6, 5), true, [id=#73]
      +- *(3) HashAggregate(keys=[d_year#4, i_brand#5, i_brand_id#6], functions=[partial_sum(UnscaledValue(ss_ext_sales_price#7))], output=[d_year#4, i_brand#5, i_brand_id#6, sum#74])
         +- *(3) Project [d_year#4, ss_ext_sales_price#7, i_brand_id#6, i_brand#5]
            +- *(3) BroadcastHashJoin [ss_item_sk#10], [i_item_sk#11], Inner, BuildRight, false
               :- *(3) Project [d_year#4, ss_item_sk#10, ss_ext_sales_price#7]
               :  +- *(3) BroadcastHashJoin [d_date_sk#8], [ss_sold_date_sk#9], Inner, BuildRight, false
               :     :- *(3) Project [d_date_sk#8, d_year#4]
               :     :  +- *(3) Filter ((((((isnotnull(d_moy#13) AND isnotnull(d_year#4)) AND (d_moy#13 = 12)) AND (d_year#4 = 1998)) AND (d_date_sk#8 <= 2451179)) AND (d_date_sk#8 >= 2451149)) AND isnotnull(d_date_sk#8))
               :     :     +- *(3) ColumnarToRow
               :     :        +- FileScan parquet default.date_dim[d_date_sk#8,d_year#4,d_moy#13] Batched: true, DataFilters: [isnotnull(d_moy#13), isnotnull(d_year#4), (d_moy#13 = 12), (d_year#4 = 1998), (d_d..., Format: Parquet, Location: InMemoryFileIndex[file:/Users/yi.wu/IdeaProjects/spark/sql/core/spark-warehouse/org.apache.spark...., PartitionFilters: [], PushedFilters: [IsNotNull(d_moy), IsNotNull(d_year), EqualTo(d_moy,12), EqualTo(d_year,1998), LessThanOrEqual(d_..., ReadSchema: struct<d_date_sk:int,d_year:int,d_moy:int>
               :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [id=#75]
               :        +- *(1) Filter (((isnotnull(ss_sold_date_sk#9) AND (ss_sold_date_sk#9 >= 2451149)) AND (ss_sold_date_sk#9 <= 2451179)) AND isnotnull(ss_item_sk#10))
               :           +- *(1) ColumnarToRow
               :              +- FileScan parquet default.store_sales[ss_sold_date_sk#9,ss_item_sk#10,ss_ext_sales_price#7] Batched: true, DataFilters: [isnotnull(ss_sold_date_sk#9), (ss_sold_date_sk#9 >= 2451149), (ss_sold_date_sk#9 <= ..., Format: Parquet, Location: InMemoryFileIndex[file:/Users/yi.wu/IdeaProjects/spark/sql/core/spark-warehouse/org.apache.spark...., PartitionFilters: [], PushedFilters: [IsNotNull(ss_sold_date_sk), GreaterThanOrEqual(ss_sold_date_sk,2451149), LessThanOrEqual(ss_sold..., ReadSchema: struct<ss_sold_date_sk:int,ss_item_sk:int,ss_ext_sales_price:decimal(7,2)>
               +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [id=#76]
                  +- *(2) Project [i_item_sk#11, i_brand_id#6, i_brand#5]
                     +- *(2) Filter ((isnotnull(i_manager_id#12) AND (i_manager_id#12 = 1)) AND isnotnull(i_item_sk#11))
                        +- *(2) ColumnarToRow
                           +- FileScan parquet default.item[i_item_sk#11,i_brand_id#6,i_brand#5,i_manager_id#12] Batched: true, DataFilters: [isnotnull(i_manager_id#12), (i_manager_id#12 = 1), isnotnull(i_item_sk#11)], Format: Parquet, Location: InMemoryFileIndex[file:/Users/yi.wu/IdeaProjects/spark/sql/core/spark-warehouse/org.apache.spark...., PartitionFilters: [], PushedFilters: [IsNotNull(i_manager_id), EqualTo(i_manager_id,1), IsNotNull(i_item_sk)], ReadSchema: struct<i_item_sk:int,i_brand_id:int,i_brand:string,i_manager_id:int>
