== Parsed Logical Plan ==
'GlobalLimit 100
+- 'LocalLimit 100
   +- 'Project [1 AS excess discount amount #1]
      +- 'Filter (((('i_manufact_id = 977) AND ('i_item_sk = 'cs_item_sk)) AND (('d_date >= 2000-01-27) AND ('d_date <= (cast(2000-01-27 as date) + 90 days)))) AND (('d_date_sk = 'cs_sold_date_sk) AND ('cs_ext_discount_amt > scalar-subquery#2 [])))
         :  +- 'Project [unresolvedalias((1.3 * 'avg('cs_ext_discount_amt)), None)]
         :     +- 'Filter ((('cs_item_sk = 'i_item_sk) AND (('d_date >= 2000-01-27) AND ('d_date <= (cast(2000-01-27 as date) + 90 days)))) AND ('d_date_sk = 'cs_sold_date_sk))
         :        +- 'Join Inner
         :           :- 'UnresolvedRelation [catalog_sales]
         :           +- 'UnresolvedRelation [date_dim]
         +- 'Join Inner
            :- 'Join Inner
            :  :- 'UnresolvedRelation [catalog_sales]
            :  +- 'UnresolvedRelation [item]
            +- 'UnresolvedRelation [date_dim]

== Analyzed Logical Plan ==
excess discount amount : int
GlobalLimit 100
+- LocalLimit 100
   +- Project [1 AS excess discount amount #1]
      +- Filter ((((i_manufact_id#3 = 977) AND (i_item_sk#4 = cs_item_sk#5)) AND ((d_date#6 >= cast(2000-01-27 as date)) AND (d_date#6 <= cast(2000-01-27 as date) + 90 days))) AND ((d_date_sk#7 = cs_sold_date_sk#8) AND (cast(cs_ext_discount_amt#9 as decimal(14,7)) > cast(scalar-subquery#2 [i_item_sk#4] as decimal(14,7)))))
         :  +- Aggregate [CheckOverflow((promote_precision(cast(1.3 as decimal(11,6))) * promote_precision(cast(avg(cs_ext_discount_amt#9) as decimal(11,6)))), DecimalType(14,7), true) AS (CAST(1.3 AS DECIMAL(11,6)) * CAST(avg(cs_ext_discount_amt) AS DECIMAL(11,6)))#10]
         :     +- Filter (((cs_item_sk#5 = outer(i_item_sk#4)) AND ((d_date#6 >= cast(2000-01-27 as date)) AND (d_date#6 <= cast(2000-01-27 as date) + 90 days))) AND (d_date_sk#7 = cs_sold_date_sk#8))
         :        +- Join Inner
         :           :- SubqueryAlias spark_catalog.default.catalog_sales
         :           :  +- Relation[cs_sold_date_sk#8,cs_sold_time_sk#11,cs_ship_date_sk#12,cs_bill_customer_sk#13,cs_bill_cdemo_sk#14,cs_bill_hdemo_sk#15,cs_bill_addr_sk#16,cs_ship_customer_sk#17,cs_ship_cdemo_sk#18,cs_ship_hdemo_sk#19,cs_ship_addr_sk#20,cs_call_center_sk#21,cs_catalog_page_sk#22,cs_ship_mode_sk#23,cs_warehouse_sk#24,cs_item_sk#5,cs_promo_sk#25,cs_order_number#26,cs_quantity#27,cs_wholesale_cost#28,cs_list_price#29,cs_sales_price#30,cs_ext_discount_amt#9,cs_ext_sales_price#31,... 10 more fields] parquet
         :           +- SubqueryAlias spark_catalog.default.date_dim
         :              +- Relation[d_date_sk#7,d_date_id#32,d_date#6,d_month_seq#33,d_week_seq#34,d_quarter_seq#35,d_year#36,d_dow#37,d_moy#38,d_dom#39,d_qoy#40,d_fy_year#41,d_fy_quarter_seq#42,d_fy_week_seq#43,d_day_name#44,d_quarter_name#45,d_holiday#46,d_weekend#47,d_following_holiday#48,d_first_dom#49,d_last_dom#50,d_same_day_ly#51,d_same_day_lq#52,d_current_day#53,... 4 more fields] parquet
         +- Join Inner
            :- Join Inner
            :  :- SubqueryAlias spark_catalog.default.catalog_sales
            :  :  +- Relation[cs_sold_date_sk#8,cs_sold_time_sk#11,cs_ship_date_sk#12,cs_bill_customer_sk#13,cs_bill_cdemo_sk#14,cs_bill_hdemo_sk#15,cs_bill_addr_sk#16,cs_ship_customer_sk#17,cs_ship_cdemo_sk#18,cs_ship_hdemo_sk#19,cs_ship_addr_sk#20,cs_call_center_sk#21,cs_catalog_page_sk#22,cs_ship_mode_sk#23,cs_warehouse_sk#24,cs_item_sk#5,cs_promo_sk#25,cs_order_number#26,cs_quantity#27,cs_wholesale_cost#28,cs_list_price#29,cs_sales_price#30,cs_ext_discount_amt#9,cs_ext_sales_price#31,... 10 more fields] parquet
            :  +- SubqueryAlias spark_catalog.default.item
            :     +- Relation[i_item_sk#4,i_item_id#54,i_rec_start_date#55,i_rec_end_date#56,i_item_desc#57,i_current_price#58,i_wholesale_cost#59,i_brand_id#60,i_brand#61,i_class_id#62,i_class#63,i_category_id#64,i_category#65,i_manufact_id#3,i_manufact#66,i_size#67,i_formulation#68,i_color#69,i_units#70,i_container#71,i_manager_id#72,i_product_name#73] parquet
            +- SubqueryAlias spark_catalog.default.date_dim
               +- Relation[d_date_sk#7,d_date_id#32,d_date#6,d_month_seq#33,d_week_seq#34,d_quarter_seq#35,d_year#36,d_dow#37,d_moy#38,d_dom#39,d_qoy#40,d_fy_year#41,d_fy_quarter_seq#42,d_fy_week_seq#43,d_day_name#44,d_quarter_name#45,d_holiday#46,d_weekend#47,d_following_holiday#48,d_first_dom#49,d_last_dom#50,d_same_day_ly#51,d_same_day_lq#52,d_current_day#53,... 4 more fields] parquet

== Optimized Logical Plan ==
GlobalLimit 100
+- LocalLimit 100
   +- Project [1 AS excess discount amount #1]
      +- Join Inner, (d_date_sk#7 = cs_sold_date_sk#8)
         :- Project [cs_sold_date_sk#8]
         :  +- Join Inner, ((cast(cs_ext_discount_amt#9 as decimal(14,7)) > (CAST(1.3 AS DECIMAL(11,6)) * CAST(avg(cs_ext_discount_amt) AS DECIMAL(11,6)))#10) AND (cs_item_sk#5#74 = i_item_sk#4))
         :     :- Project [cs_sold_date_sk#8, cs_ext_discount_amt#9, i_item_sk#4]
         :     :  +- Join Inner, (i_item_sk#4 = cs_item_sk#5)
         :     :     :- Project [cs_sold_date_sk#8, cs_item_sk#5, cs_ext_discount_amt#9]
         :     :     :  +- Filter ((isnotnull(cs_item_sk#5) AND isnotnull(cs_ext_discount_amt#9)) AND isnotnull(cs_sold_date_sk#8))
         :     :     :     +- Relation[cs_sold_date_sk#8,cs_sold_time_sk#11,cs_ship_date_sk#12,cs_bill_customer_sk#13,cs_bill_cdemo_sk#14,cs_bill_hdemo_sk#15,cs_bill_addr_sk#16,cs_ship_customer_sk#17,cs_ship_cdemo_sk#18,cs_ship_hdemo_sk#19,cs_ship_addr_sk#20,cs_call_center_sk#21,cs_catalog_page_sk#22,cs_ship_mode_sk#23,cs_warehouse_sk#24,cs_item_sk#5,cs_promo_sk#25,cs_order_number#26,cs_quantity#27,cs_wholesale_cost#28,cs_list_price#29,cs_sales_price#30,cs_ext_discount_amt#9,cs_ext_sales_price#31,... 10 more fields] parquet
         :     :     +- Project [i_item_sk#4]
         :     :        +- Filter ((isnotnull(i_manufact_id#3) AND (i_manufact_id#3 = 977)) AND isnotnull(i_item_sk#4))
         :     :           +- Relation[i_item_sk#4,i_item_id#54,i_rec_start_date#55,i_rec_end_date#56,i_item_desc#57,i_current_price#58,i_wholesale_cost#59,i_brand_id#60,i_brand#61,i_class_id#62,i_class#63,i_category_id#64,i_category#65,i_manufact_id#3,i_manufact#66,i_size#67,i_formulation#68,i_color#69,i_units#70,i_container#71,i_manager_id#72,i_product_name#73] parquet
         :     +- Filter isnotnull((CAST(1.3 AS DECIMAL(11,6)) * CAST(avg(cs_ext_discount_amt) AS DECIMAL(11,6)))#10)
         :        +- Aggregate [cs_item_sk#5], [CheckOverflow((1.300000 * promote_precision(cast((avg(UnscaledValue(cs_ext_discount_amt#9)) / 100.0) as decimal(11,6)))), DecimalType(14,7), true) AS (CAST(1.3 AS DECIMAL(11,6)) * CAST(avg(cs_ext_discount_amt) AS DECIMAL(11,6)))#10, cs_item_sk#5 AS cs_item_sk#5#74]
         :           +- Project [cs_item_sk#5, cs_ext_discount_amt#9]
         :              +- Join Inner, (d_date_sk#7 = cs_sold_date_sk#8)
         :                 :- Project [cs_sold_date_sk#8, cs_item_sk#5, cs_ext_discount_amt#9]
         :                 :  +- Filter (isnotnull(cs_sold_date_sk#8) AND isnotnull(cs_item_sk#5))
         :                 :     +- Relation[cs_sold_date_sk#8,cs_sold_time_sk#11,cs_ship_date_sk#12,cs_bill_customer_sk#13,cs_bill_cdemo_sk#14,cs_bill_hdemo_sk#15,cs_bill_addr_sk#16,cs_ship_customer_sk#17,cs_ship_cdemo_sk#18,cs_ship_hdemo_sk#19,cs_ship_addr_sk#20,cs_call_center_sk#21,cs_catalog_page_sk#22,cs_ship_mode_sk#23,cs_warehouse_sk#24,cs_item_sk#5,cs_promo_sk#25,cs_order_number#26,cs_quantity#27,cs_wholesale_cost#28,cs_list_price#29,cs_sales_price#30,cs_ext_discount_amt#9,cs_ext_sales_price#31,... 10 more fields] parquet
         :                 +- Project [d_date_sk#7]
         :                    +- Filter (((isnotnull(d_date#6) AND (d_date#6 >= 10983)) AND (d_date#6 <= 11073)) AND isnotnull(d_date_sk#7))
         :                       +- Relation[d_date_sk#7,d_date_id#32,d_date#6,d_month_seq#33,d_week_seq#34,d_quarter_seq#35,d_year#36,d_dow#37,d_moy#38,d_dom#39,d_qoy#40,d_fy_year#41,d_fy_quarter_seq#42,d_fy_week_seq#43,d_day_name#44,d_quarter_name#45,d_holiday#46,d_weekend#47,d_following_holiday#48,d_first_dom#49,d_last_dom#50,d_same_day_ly#51,d_same_day_lq#52,d_current_day#53,... 4 more fields] parquet
         +- Project [d_date_sk#7]
            +- Filter (((isnotnull(d_date#6) AND (d_date#6 >= 10983)) AND (d_date#6 <= 11073)) AND isnotnull(d_date_sk#7))
               +- Relation[d_date_sk#7,d_date_id#32,d_date#6,d_month_seq#33,d_week_seq#34,d_quarter_seq#35,d_year#36,d_dow#37,d_moy#38,d_dom#39,d_qoy#40,d_fy_year#41,d_fy_quarter_seq#42,d_fy_week_seq#43,d_day_name#44,d_quarter_name#45,d_holiday#46,d_weekend#47,d_following_holiday#48,d_first_dom#49,d_last_dom#50,d_same_day_ly#51,d_same_day_lq#52,d_current_day#53,... 4 more fields] parquet

== Physical Plan ==
CollectLimit 100
+- *(6) Project [1 AS excess discount amount #1]
   +- *(6) BroadcastHashJoin [cs_sold_date_sk#8], [d_date_sk#7], Inner, BuildRight, false
      :- *(6) Project [cs_sold_date_sk#8]
      :  +- *(6) BroadcastHashJoin [i_item_sk#4], [cs_item_sk#5#74], Inner, BuildRight, (cast(cs_ext_discount_amt#9 as decimal(14,7)) > (CAST(1.3 AS DECIMAL(11,6)) * CAST(avg(cs_ext_discount_amt) AS DECIMAL(11,6)))#10), false
      :     :- *(6) Project [cs_sold_date_sk#8, cs_ext_discount_amt#9, i_item_sk#4]
      :     :  +- *(6) BroadcastHashJoin [cs_item_sk#5], [i_item_sk#4], Inner, BuildRight, false
      :     :     :- *(6) Project [cs_sold_date_sk#8, cs_item_sk#5, cs_ext_discount_amt#9]
      :     :     :  +- *(6) Filter ((isnotnull(cs_item_sk#5) AND isnotnull(cs_ext_discount_amt#9)) AND isnotnull(cs_sold_date_sk#8))
      :     :     :     +- *(6) ColumnarToRow
      :     :     :        +- FileScan parquet default.catalog_sales[cs_sold_date_sk#8,cs_item_sk#5,cs_ext_discount_amt#9] Batched: true, DataFilters: [isnotnull(cs_item_sk#5), isnotnull(cs_ext_discount_amt#9), isnotnull(cs_sold_date_sk#8)], Format: Parquet, Location: InMemoryFileIndex[file:/Users/yi.wu/IdeaProjects/spark/sql/core/spark-warehouse/org.apache.spark...., PartitionFilters: [], PushedFilters: [IsNotNull(cs_item_sk), IsNotNull(cs_ext_discount_amt), IsNotNull(cs_sold_date_sk)], ReadSchema: struct<cs_sold_date_sk:int,cs_item_sk:int,cs_ext_discount_amt:decimal(7,2)>
      :     :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [id=#75]
      :     :        +- *(1) Project [i_item_sk#4]
      :     :           +- *(1) Filter ((isnotnull(i_manufact_id#3) AND (i_manufact_id#3 = 977)) AND isnotnull(i_item_sk#4))
      :     :              +- *(1) ColumnarToRow
      :     :                 +- FileScan parquet default.item[i_item_sk#4,i_manufact_id#3] Batched: true, DataFilters: [isnotnull(i_manufact_id#3), (i_manufact_id#3 = 977), isnotnull(i_item_sk#4)], Format: Parquet, Location: InMemoryFileIndex[file:/Users/yi.wu/IdeaProjects/spark/sql/core/spark-warehouse/org.apache.spark...., PartitionFilters: [], PushedFilters: [IsNotNull(i_manufact_id), EqualTo(i_manufact_id,977), IsNotNull(i_item_sk)], ReadSchema: struct<i_item_sk:int,i_manufact_id:int>
      :     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[1, int, true] as bigint)),false), [id=#76]
      :        +- *(4) Filter isnotnull((CAST(1.3 AS DECIMAL(11,6)) * CAST(avg(cs_ext_discount_amt) AS DECIMAL(11,6)))#10)
      :           +- *(4) HashAggregate(keys=[cs_item_sk#5], functions=[avg(UnscaledValue(cs_ext_discount_amt#9))], output=[(CAST(1.3 AS DECIMAL(11,6)) * CAST(avg(cs_ext_discount_amt) AS DECIMAL(11,6)))#10, cs_item_sk#5#74])
      :              +- Exchange hashpartitioning(cs_item_sk#5, 5), true, [id=#77]
      :                 +- *(3) HashAggregate(keys=[cs_item_sk#5], functions=[partial_avg(UnscaledValue(cs_ext_discount_amt#9))], output=[cs_item_sk#5, sum#78, count#79])
      :                    +- *(3) Project [cs_item_sk#5, cs_ext_discount_amt#9]
      :                       +- *(3) BroadcastHashJoin [cs_sold_date_sk#8], [d_date_sk#7], Inner, BuildRight, false
      :                          :- *(3) Project [cs_sold_date_sk#8, cs_item_sk#5, cs_ext_discount_amt#9]
      :                          :  +- *(3) Filter (isnotnull(cs_sold_date_sk#8) AND isnotnull(cs_item_sk#5))
      :                          :     +- *(3) ColumnarToRow
      :                          :        +- FileScan parquet default.catalog_sales[cs_sold_date_sk#8,cs_item_sk#5,cs_ext_discount_amt#9] Batched: true, DataFilters: [isnotnull(cs_sold_date_sk#8), isnotnull(cs_item_sk#5)], Format: Parquet, Location: InMemoryFileIndex[file:/Users/yi.wu/IdeaProjects/spark/sql/core/spark-warehouse/org.apache.spark...., PartitionFilters: [], PushedFilters: [IsNotNull(cs_sold_date_sk), IsNotNull(cs_item_sk)], ReadSchema: struct<cs_sold_date_sk:int,cs_item_sk:int,cs_ext_discount_amt:decimal(7,2)>
      :                          +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [id=#80]
      :                             +- *(2) Project [d_date_sk#7]
      :                                +- *(2) Filter (((isnotnull(d_date#6) AND (d_date#6 >= 10983)) AND (d_date#6 <= 11073)) AND isnotnull(d_date_sk#7))
      :                                   +- *(2) ColumnarToRow
      :                                      +- FileScan parquet default.date_dim[d_date_sk#7,d_date#6] Batched: true, DataFilters: [isnotnull(d_date#6), (d_date#6 >= 10983), (d_date#6 <= 11073), isnotnull(d_date_sk#7)], Format: Parquet, Location: InMemoryFileIndex[file:/Users/yi.wu/IdeaProjects/spark/sql/core/spark-warehouse/org.apache.spark...., PartitionFilters: [], PushedFilters: [IsNotNull(d_date), GreaterThanOrEqual(d_date,2000-01-27), LessThanOrEqual(d_date,2000-04-26), Is..., ReadSchema: struct<d_date_sk:int,d_date:date>
      +- ReusedExchange [d_date_sk#7], BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, true] as bigint)),false), [id=#80]
